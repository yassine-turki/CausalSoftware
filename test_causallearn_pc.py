# -*- coding: utf-8 -*-
"""Test_CausalLearn_PC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PV_5EP90jQeAQ6IWsP3Xd3uqqSoZWGeP

# Imports
"""


from causallearn.search.ConstraintBased.PC import pc
from causallearn.utils.GraphUtils import GraphUtils
import pandas as pd
import numpy as np
import graphviz
import pydot
from causallearn.utils.cit import fisherz, mv_fisherz
from causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge
from causallearn.utils.PCUtils.BackgroundKnowledgeOrientUtils import \
    orient_by_background_knowledge
from causallearn.graph.GraphClass import CausalGraph
from causallearn.graph.GraphNode import GraphNode

import sys

file_path = sys.argv[1] 

"""# Useful functions"""

def load_and_check_data(file_path, dropna=False, drop_objects=False):
  """
  Loads dataset and checks if there are any NaN values and non numerical data
  Returns an np array of the values in the dataframe, and a list of labels

  file_path: file from where to extract the data
  dropna: bool to indicate if we drop all NaN values. default: False
  drop_objects: bool to indicate if we drop all non numerical data. default: False

  """

  data=pd.read_csv(file_path,index_col=0)
  cols_containing_nan = []

  # Check for NaN values in each column
  for col in data.columns:
      if data[col].isnull().any():
          cols_containing_nan.append(col)
  if len(cols_containing_nan) !=0:
    print("Columns with missing values:", cols_containing_nan)
    if dropna==False:
      print("Please remove missing values, or set dropna to True")
      return None
    else:
      data=data.dropna()

  #Check for non numerical data:

  object_columns = data.select_dtypes(include=['object']).columns
  if len(object_columns) > 0:
    print("Columns of object type found:", object_columns)
    if drop_objects==False:
      print("Please remove non numerical data, or set drop_objects to True")
    else:
      data=data.drop(columns=object_columns)

  return data.values, data.columns

def run_pc(dataset,labels,alpha=0.05, indep_test='fisherz', stable=True, uc_rule=0, uc_priority=2, mvpc=False, correction_name='MV_Crtn_Fisher_Z', background_knowledge=None, verbose=False, show_progress=True):

  """
  data: numpy.ndarray, shape (n_samples, n_features). Data, where n_samples is the number of samples and n_features is the number of features.

  alpha: desired significance level (float) in (0, 1). Default: 0.05.

  indep_test: string, name of the independence test method. Default: ‘fisherz’.
    “fisherz”: Fisher’s Z conditional independence test.

    “chisq”: Chi-squared conditional independence test.

    “gsq”: G-squared conditional independence test.

    “kci”: kernel-based conditional independence test. (As a kernel method, its complexity is cubic in the sample size, so it might be slow if the same size is not small.)

    “mv_fisherz”: Missing-value Fisher’s Z conditional independence test.

  stable: run stabilized skeleton discovery if True. Default: True.

  uc_rule: how unshielded colliders are oriented. Default: 0.
    0: run uc_sepset.

    1: run maxP. Orient an unshielded triple X-Y-Z as a collider with an additional CI test.

    2: run definiteMaxP. Orient only the definite colliders in the skeleton and keep track of all the definite non-colliders as well.

  uc_priority: rule of resolving conflicts between unshielded colliders. Default: 2.
    -1: whatever is default in uc_rule.

    0: overwrite.

    1: orient bi-directed.

    2: prioritize existing colliders.

    3: prioritize stronger colliders.

    4: prioritize stronger* colliders.

  mvpc: use missing-value PC or not. Default: False.

  correction_name. Missing value correction if using missing-value PC. Default: ‘MV_Crtn_Fisher_Z’

  background_knowledge: class BackgroundKnowledge. Add prior edges according to assigned causal connections. Default: None. For detailed usage, please kindly refer to its usage example.

  verbose: True iff verbose output should be printed. Default: False.

  show_progress: True iff the algorithm progress should be show in console. Default: True.


"""

  if background_knowledge is not None: # Create a background knowledge object

  # Run the algorithm once without background knowledge to get the nodes (to be changed later)
    cg_without_background_knowledge=pc(dataset,alpha=alpha, indep_test=indep_test, stable=stable, uc_rule=uc_rule, uc_priority=uc_priority, mvpc=mvpc, correction_name=correction_name, background_knowledge=None, verbose=False, show_progress=False)
    nodes = cg_without_background_knowledge.G.get_nodes()

    node_map = {} #Provide a mapping between names and nodes
    for i, label in enumerate(labels):
        node_map[label] = nodes[i]

    bk = BackgroundKnowledge()
    for i, sublist in enumerate(background_knowledge): #create tiers
      for j in range(len(sublist)):
        node = node_map[sublist[j]]
        bk.add_node_to_tier(node, i)

  else:
    bk = None

  # Run the algorithm

  cg = pc(dataset,alpha=alpha, indep_test=indep_test, stable=stable, uc_rule=uc_rule, uc_priority=uc_priority, mvpc=mvpc, correction_name=correction_name, background_knowledge=bk, verbose=verbose, show_progress=show_progress)

  return cg

def draw_graph(graph, labels, filename=None):
  """
  Draw the pydot graph

  graph: CausalGraph object
  labels: data.columns
  filename: if you wish to save the file
  """

  if filename==None:
    graph.draw_pydot_graph(labels = labels)
  else:
    pyd = GraphUtils.to_pydot(graph.G, labels = labels)
    if filename[-3:]=="png":
      pyd.write_png(filename)
    elif filename[-4:]=="jpeg":
      pyd.write_jpeg(filename)
    elif filename[-3:]=="pdf":
      pyd.write_png(filename)
    else:
      pyd.write_png(filename+".png")
"""
def delete_path(graph, labels, path_to_delete):

  deletes a selected path

  graph is a CausalGraph object

  labels: labels of the dataset

  path_to_delete: a list containing two nodes. For example ["Sex","Race"]. This will delete the path from "Sex" to "Race"


  column_to_index = {col: i for i, col in enumerate(labels)}
  if path_to_delete[0] not in column_to_index.keys() or path_to_delete[1] not in column_to_index.keys():
    print("Error: given path is not in the labels for the data")
    return graph

  # Find the indices of the nodes
  node1_index = column_to_index[path_to_delete[0]]
  node2_index = column_to_index[path_to_delete[1]]

  # Remove the edge from node1 to node2
  graph.G.graph[node1_index, node2_index] = 0

  return graph

def add_path(graph, labels, path_to_add):

  adds a new path

  graph is a CausalGraph object

  labels: labels of the dataset

  path_to_add: a list containing two nodes. For example ["Sex","Race"]. This will add the path from "Sex" to "Race"


  column_to_index = {col: i for i, col in enumerate(labels)}
  if path_to_add[0] not in column_to_index.keys() or path_to_add[1] not in column_to_index.keys():
    print("Error: given path is not in the labels for the data")
    return graph

  # Find the indices of the nodes
  node1_index = column_to_index[path_to_add[0]]
  node2_index = column_to_index[path_to_add[1]]

  # Add the edge from node1 to node2
  graph.G.graph[node2_index, node1_index] = 1
  graph.G.graph[node1_index, node2_index] = -1


  return graph
"""

def run_pc_and_draw(file_path_data, alpha=0.05, indep_test='fisherz', stable=True, uc_rule=0, uc_priority=2, mvpc=False, correction_name='MV_Crtn_Fisher_Z', background_knowledge=None, verbose=False, show_progress=True, file_path_graph=None):

  """
  loads the data, runs the pc algorithm and draws the graph

  """

  dataset, labels = load_and_check_data(file_path_data)
  g=run_pc(dataset,labels,alpha=alpha, indep_test=indep_test, stable=stable, uc_rule=uc_rule, uc_priority=uc_priority, mvpc=mvpc, correction_name=correction_name, background_knowledge=background_knowledge, verbose=verbose, show_progress=show_progress)
  draw_graph(g,labels, file_path_graph)
  return g

"""# Example: adult_cleaned_bin"""

#file_path="adult_cleaned_bin.csv"
g=run_pc_and_draw(file_path)

"""Now let's say we want to add background knowledge and put "occupation" in **Tier 1** and "Sex" in **Tier 2**"""

#file_path="adult_cleaned_bin.csv"
_,labels=load_and_check_data(file_path)
background = [["occupation"], ["Sex"]]
pc_with_background_knowledge=run_pc_and_draw(file_path,background_knowledge=background)

"""Now, we want to delete the path from income to race"""

pc_with_background_knowledge=delete_path(pc_with_background_knowledge, labels, ["income","race"])
draw_graph(pc_with_background_knowledge, labels, filename=None)

"""Now, we we want to add a path from relationship to occupation"""

pc_with_background_knowledge=add_path(pc_with_background_knowledge, labels, ["relationship","occupation"])
draw_graph(pc_with_background_knowledge, labels, filename=None)

"""# This is old and only kept here for future reference"""

# data=np.loadtxt(file_path, delimiter=",",skiprows=1)
# with open(file_path, "r") as file:
#     labels = file.readline().strip().split(",")
# cg_without_background_knowledge = pc(data, 0.05,fisherz)  # Run PC and obtain the estimated graph (CausalGraph object)

# nodes = cg_without_background_knowledge.G.get_nodes()
# cg_without_background_knowledge.draw_pydot_graph(labels=labels)

# node_map = {}
# for i, label in enumerate(labels):
#     node_map[label] = nodes[i]
# node_workclass = node_map["workclass"]
# node_sex = node_map["Sex"]

# bk = BackgroundKnowledge() \
#     .add_node_to_tier(node_workclass, 2).add_node_to_tier(node_sex, 1)
# cg_with_background_knowledge = pc(data, 0.05, mv_fisherz, True, 0, 0, mvpc=True, background_knowledge=bk)
# cg_with_background_knowledge.draw_pydot_graph(labels=labels)

# def run_pc(dataset,labels,alpha=0.05, indep_test='fisherz', stable=True, uc_rule=0, uc_priority=2, mvpc=False, correction_name='MV_Crtn_Fisher_Z', background_knowledge=None, verbose=False, show_progress=True):

#   """
#   data: numpy.ndarray, shape (n_samples, n_features). Data, where n_samples is the number of samples and n_features is the number of features.

#   alpha: desired significance level (float) in (0, 1). Default: 0.05.

#   indep_test: string, name of the independence test method. Default: ‘fisherz’.
#     “fisherz”: Fisher’s Z conditional independence test.

#     “chisq”: Chi-squared conditional independence test.

#     “gsq”: G-squared conditional independence test.

#     “kci”: kernel-based conditional independence test. (As a kernel method, its complexity is cubic in the sample size, so it might be slow if the same size is not small.)

#     “mv_fisherz”: Missing-value Fisher’s Z conditional independence test.

#   stable: run stabilized skeleton discovery if True. Default: True.

#   uc_rule: how unshielded colliders are oriented. Default: 0.
#     0: run uc_sepset.

#     1: run maxP. Orient an unshielded triple X-Y-Z as a collider with an additional CI test.

#     2: run definiteMaxP. Orient only the definite colliders in the skeleton and keep track of all the definite non-colliders as well.

#   uc_priority: rule of resolving conflicts between unshielded colliders. Default: 2.
#     -1: whatever is default in uc_rule.

#     0: overwrite.

#     1: orient bi-directed.

#     2: prioritize existing colliders.

#     3: prioritize stronger colliders.

#     4: prioritize stronger* colliders.

#   mvpc: use missing-value PC or not. Default: False.

#   correction_name. Missing value correction if using missing-value PC. Default: ‘MV_Crtn_Fisher_Z’

#   background_knowledge: class BackgroundKnowledge. Add prior edges according to assigned causal connections. Default: None. For detailed usage, please kindly refer to its usage example.

#   verbose: True iff verbose output should be printed. Default: False.

#   show_progress: True iff the algorithm progress should be show in console. Default: True.

#   two_way: Set to True if the nodes in background knowledge should not be connected in both directions. Default: False

# """

#   if background_knowledge is not None: # Create a background knowledge object
#     node_map = {}
#     for i, label in enumerate(labels):
#       node_map[label] = i
#     bk=BackgroundKnowledge()
#     for i in range(len(background_knowledge)-1,-1,-1): # iterating through tiers in reverse order
#       for j in range(len(background_knowledge[i])): #iterating through the nodes in the tier we're in
#         for k in range(i): #iterate over the remaining tiers
#           for p in range(len(background_knowledge[k])): #iterating through the first tiers' nodes
#             print(background_knowledge[k][p])
#             print(background_knowledge[i][j])
#             node_1 = GraphNode(background_knowledge[k][p])
#             node_2 = GraphNode(background_knowledge[i][j])
#             bk=bk.add_forbidden_by_node(node_1, node_2)
#             # node_1 = node_map[background_knowledge[k][p]]
#             # node_2 = node_map[background_knowledge[i][j]]
#             # bk.add_forbidden_by_node(node_1, node_2)
#   else:
#     bk = None

#   # Run the algorithm

#   cg = pc(dataset,alpha=alpha, indep_test=indep_test, stable=stable, uc_rule=uc_rule, uc_priority=uc_priority, mvpc=mvpc, correction_name=correction_name, background_knowledge=bk, verbose=verbose, show_progress=show_progress)

#   return cg