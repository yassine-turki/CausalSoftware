# -*- coding: utf-8 -*-
"""Test_Dowhy_CausalLearn_GES.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13PSB3V1OvmW1PsprogVTIcb9S9UvS_nW

# Imports
"""

# !pip install dowhy
# !pip install causal-learn
# !sudo apt-get install python3-dev graphviz libgraphviz-dev pkg-config
# !sudo pip install pygraphviz

from causallearn.search.ScoreBased.GES import ges
from causallearn.utils.GraphUtils import GraphUtils
import pandas as pd
import numpy as np
import graphviz
import pydot
from IPython.display import Image, display
from causallearn.utils.cit import fisherz, mv_fisherz
from causallearn.graph.GraphClass import CausalGraph
from causallearn.graph.GraphNode import GraphNode
from causallearn.search.ConstraintBased.PC import pc
from causallearn.graph.GraphClass import CausalGraph
from causallearn.graph.GraphNode import GraphNode
import networkx as nx
import dowhy
from dowhy import CausalModel
import dowhy.datasets
from graphviz import Digraph
from dowhy.causal_estimators import (
    causalml,
    distance_matching_estimator,
    econml,
    generalized_linear_model_estimator,
    instrumental_variable_estimator,
    linear_regression_estimator,
    propensity_score_estimator,
    propensity_score_matching_estimator,
    propensity_score_stratification_estimator,
    propensity_score_weighting_estimator,
    regression_discontinuity_estimator,
    regression_estimator,
    two_stage_regression_estimator
)
import statsmodels.api as sm

def load_and_check_data(file_path, dropna=False, drop_objects=False):
  """
  Loads dataset and checks if there are any NaN values and non numerical data
  Returns an np array of the values in the dataframe, and a list of labels

  file_path: file from where to extract the data
  dropna: bool to indicate if we drop all NaN values. default: False
  drop_objects: bool to indicate if we drop all non numerical data. default: False

  """

  data=pd.read_csv(file_path)
  cols_containing_nan = []

  # Check for NaN values in each column
  for col in data.columns:
      if data[col].isnull().any():
          cols_containing_nan.append(col)
  if len(cols_containing_nan) !=0:
    print("Columns with missing values:", cols_containing_nan)
    if dropna==False:
      print("Please remove missing values, or set dropna to True")
      return None
    else:
      data=data.dropna()

  #Check for non numerical data:

  object_columns = data.select_dtypes(include=['object']).columns
  if len(object_columns) > 0:
    print("Columns of object type found:", object_columns)
    if drop_objects==False:
      print("Please remove non numerical data, or set drop_objects to True")
    else:
      data=data.drop(columns=object_columns)

  return data.values, data.columns

def run_ges(data, score_func = "local_score_BIC", maxP = None, parameters = None):

  """
  data: numpy.ndarray, shape (n_samples, n_features). Data, where n_samples is the number of samples and n_features is the number of features.

  score_func: The score function you would like to use, including (see score_functions.). Default: ‘local_score_BIC’.
    “local_score_BIC”: BIC score.

    “local_score_BDeu”: BDeu score.

    “local_score_cv_general”: Generalized score with cross validation for data with single-dimensional variables.

    “local_score_marginal_general”: Generalized score with marginal likelihood for data with single-dimensional variables.

    “local_score_cv_multi”: Generalized score with cross validation for data with multi-dimensional variables.

    “local_score_marginal_multi”: Generalized score with marginal likelihood for data with multi-dimensional variables.

  maxP: Allowed maximum number of parents when searching the graph. Default: None.

  parameters: Needed when using CV likelihood. Default: None.
    parameters[‘kfold’]: k-fold cross validation.

    parameters[‘lambda’]: regularization parameter.

    parameters[‘dlabel’]: for variables with multi-dimensions, indicate which dimensions belong to the i-th variable.

"""

  # Run the algorithm

  cg = ges(data, score_func = score_func, maxP = maxP, parameters = parameters)

  return cg

def draw_graph(graph, labels, filename=None):
    """
    Draw the pydot graph
    graph: CausalGraph object
    labels: data.columns
    filename: if you wish to save the file
    """

    adjacency_matrix = graph['G'].graph
    learned_graph = nx.DiGraph()
    undirected_paths = set() # Set to check if we have undirected_paths

    # Add directed edges based on the condition
    for i in range(len(adjacency_matrix)):
        for j in range(len(adjacency_matrix[0])):
            if adjacency_matrix[i][j] == -1 and adjacency_matrix[j][i] == 1:
                learned_graph.add_edge(labels[i], labels[j])
            elif ((adjacency_matrix[i][j] == -1 and adjacency_matrix[j][i] == -1) or (adjacency_matrix[i][j] == 1 and adjacency_matrix[j][i] == 1)) and ((labels[i],labels[j]) not in undirected_paths and (labels[j],labels[i]) not in undirected_paths):
              learned_graph.add_edge(labels[i], labels[j], style="dashed", arrowhead="none")
              undirected_paths.add((labels[i],labels[j]))

    pos = nx.circular_layout(learned_graph)
    pydot_graph = nx.drawing.nx_pydot.to_pydot(learned_graph)

    png_data = pydot_graph.create_png()
    if filename is None:
        with open("graph.png", "wb") as f:
            f.write(png_data)
    else:
        if not filename.lower().endswith((".png", ".jpeg", ".pdf")):
            filename += ".png"
        with open(filename, "wb") as f:
            f.write(png_data)

def delete_path(graph, labels, path_to_delete):

  """
  deletes a selected path

  graph is a CausalGraph object

  labels: labels of the dataset

  path_to_delete: a list containing two nodes. For example ["Sex","Race"]. This will delete the path from "Sex" to "Race"

  """

  column_to_index = {col: i for i, col in enumerate(labels)}
  if path_to_delete[0] not in column_to_index.keys() or path_to_delete[1] not in column_to_index.keys():
    print("Error: given path is not in the labels for the data")
    return graph

  # Find the indices of the nodes
  node1_index = column_to_index[path_to_delete[0]]
  node2_index = column_to_index[path_to_delete[1]]

  # Remove the edge from node1 to node2
  graph["G"].graph[node1_index, node2_index] = 0

  return graph

def add_path(graph, labels, path_to_add):

  """
  adds a new path

  graph is a CausalGraph object

  labels: labels of the dataset

  path_to_add: a list containing two nodes. For example ["Sex","Race"]. This will add the path from "Sex" to "Race"

  """

  column_to_index = {col: i for i, col in enumerate(labels)}
  if path_to_add[0] not in column_to_index.keys() or path_to_add[1] not in column_to_index.keys():
    print("Error: given path is not in the labels for the data")
    return graph

  # Find the indices of the nodes
  node1_index = column_to_index[path_to_add[0]]
  node2_index = column_to_index[path_to_add[1]]

  # Add the edge from node1 to node2
  graph["G"].graph[node2_index, node1_index] = 1
  graph["G"].graph[node1_index, node2_index] = -1


  return graph

def adjacency_matrix_to_gml(matrix, labels):

  """
  Given an adjacency matrix and the labels corresponding to the labels of nodes, return the same graph in gml format

  """
  G = nx.DiGraph()
  for n in labels:
    G.add_node(n)
  for i in range(len(matrix)):
    for j in range(len(matrix[0])):
      if (matrix[i][j]== 1 and matrix[j][i]== 1) or (matrix[i][j]== -1 and matrix[j][i]== -1):
        continue
      elif matrix[i][j]== -1 and matrix[j][i]== 1:
        G.add_edge(labels[i],labels[j])
  gml = list(nx.generate_gml(G))
  return gml

def create_model(g, df, treatment, outcome, common_causes = None, instruments = None, effect_modifiers = None, estimand_type = "nonparametric-ate", proceed_when_unidentifiable = True, missing_nodes_as_confounders = False, identify_vars = False):

  """
        :param g: a CausalGraph object
        :param df: a pandas dataframe containing treatment, outcome and other variables.
        :param treatment: name of the treatment variable
        :param outcome: name of the outcome variable
        :param common_causes: names of common causes of treatment and _outcome. Only used when graph is None.
        :param instruments: names of instrumental variables for the effect of treatment on outcome. Only used when graph is None.
        :param effect_modifiers: names of variables that can modify the treatment effect. If not provided, then the causal graph is used to find the effect modifiers. Estimators will return multiple different estimates based on each value of effect_modifiers.
        :param estimand_type: the type of estimand requested (currently only "nonparametric-ate" is supported). In the future, may support other specific parametric forms of identification.
        :param proceed_when_unidentifiable: does the identification proceed by ignoring potential unobserved confounders. Binary flag.
        :param missing_nodes_as_confounders: Binary flag indicating whether variables in the dataframe that are not included in the causal graph, should be  automatically included as confounder nodes.
        :param identify_vars: Variable deciding whether to compute common causes, instruments and effect modifiers while initializing the class. identify_vars should be set to False when user is providing common_causes, instruments or effect modifiers on their own(otherwise the identify_vars code can override the user provided values). Also it does not make sense if no graph is given.
        :returns: an instance of CausalModel class

  """
  labels = df.columns
  if treatment not in labels:
    print(treatment, "not in dataset. Please try another treatment variable name")
  if outcome not in labels:
    print(outcome, "not in dataset. Please try another outcome variable name")
  adjacency_matrix = g['G'].graph
  gml = adjacency_matrix_to_gml(adjacency_matrix, labels)
  model=CausalModel(
        data = df,
        treatment=[treatment],
        outcome=[outcome],
        graph="".join(gml),
        common_causes=common_causes,
        instruments=instruments,
        effect_modifiers= effect_modifiers,
        estimand_type= estimand_type,
        proceed_when_unidentifiable=proceed_when_unidentifiable,
        missing_nodes_as_confounders=missing_nodes_as_confounders,
        identify_vars=identify_vars,
        )
  return model

def find_effect(model, estimand_type=None, method_name="default", proceed_when_unidentifiable=True, optimize_backdoor=False):

        """Identify the causal effect to be estimated, using properties of the causal graph.

        :param model: A dowhy model class instance
        :param method_name: Method name for identification algorithm. ("id-algorithm" or "default")
        :param proceed_when_unidentifiable: Binary flag indicating whether identification should proceed in the presence of (potential) unobserved confounders.
        :returns: a probability expression (estimand) for the causal effect if identified, else NULL

        """
        return model.identify_effect(estimand_type = estimand_type, method_name = method_name, proceed_when_unidentifiable = proceed_when_unidentifiable, optimize_backdoor = optimize_backdoor)

def compute_effect(model, identified_estimand,
                   continuous_outcome=False,
                   method_name=None,
                   control_value=0,
                   treatment_value=1,
                   test_significance=None,
                   evaluate_effect_strength=False,
                   confidence_intervals=False,
                   target_units="ate",
                   effect_modifiers=None,
                   fit_estimator=True,
                   method_params=None):

    """Estimate the identified causal effect.

    Currently requires an explicit method name to be specified. Method names follow the convention of identification method followed by the specific estimation method: "[backdoor/iv].estimation_method_name". Following methods are supported.
        * Propensity Score Matching: "backdoor.propensity_score_matching"
        * Propensity Score Stratification: "backdoor.propensity_score_stratification"
        * Propensity Score-based Inverse Weighting: "backdoor.propensity_score_weighting"
        * Linear Regression: "backdoor.linear_regression"
        * Generalized Linear Models (e.g., logistic regression): "backdoor.generalized_linear_model"
        * Instrumental Variables: "iv.instrumental_variable"
        * Regression Discontinuity: "iv.regression_discontinuity"

    In addition, you can directly call any of the EconML estimation methods. The convention is "backdoor.econml.path-to-estimator-class". For example, for the double machine learning estimator ("DML" class) that is located inside "dml" module of EconML, you can use the method name, "backdoor.econml.dml.DML". CausalML estimators can also be called. See this demo notebook: https://py-why.github.io/dowhy/example_notebooks/dowhy-conditional-treatment-effects.html.

    :param model: A dowhy_model.
    :param identified_estimand: A probability expression that represents the effect to be estimated. Output of CausalModel.identify_effect method.
    :param continuous_outcome: Bool to specify if the outcome is continuous.
    :param method_name: Name of the estimation method to be used. If not specified:
        - If backdoor is available:
            - If the outcome is continuous, method_name = "backdoor.linear_regression"
            - If the outcome is binary, method_name = "backdoor.propensity_score_stratification"
        - If no backdoor estimand:
            - If IV exists, method_name = "iv.instrumental_variable"
    :param control_value: Value of the treatment in the control group, for effect estimation. If treatment is multi-variate, this can be a list.
    :param treatment_value: Value of the treatment in the treated group, for effect estimation. If treatment is multi-variate, this can be a list.
    :param test_significance: Binary flag on whether to additionally do a statistical significance test for the estimate.
    :param evaluate_effect_strength: (Experimental) Binary flag on whether to estimate the relative strength of the treatment's effect. This measure can be used to compare different treatments for the same outcome (by running this method with different treatments sequentially).
    :param confidence_intervals: (Experimental) Binary flag indicating whether confidence intervals should be computed.
    :param target_units: (Experimental) The units for which the treatment effect should be estimated. This can be of three types. (1) A string for common specifications of target units (namely, "ate", "att", and "atc"), (2) a lambda function that can be used as an index for the data (pandas DataFrame), or (3) a new DataFrame that contains values of the effect_modifiers and effect will be estimated only for this new data.
    :param effect_modifiers: Names of effect modifier variables can be (optionally) specified here too, since they do not affect identification. If None, the effect_modifiers from the CausalModel are used.
    :param fit_estimator: Boolean flag on whether to fit the estimator. Setting it to False is useful to estimate the effect on new data using a previously fitted estimator.
    :param method_params: Dictionary containing any method-specific parameters. These are passed directly to the estimating method. See the docs for each estimation method for allowed method-specific params.
    :returns: An instance of the CausalEstimate class, containing the causal effect estimate and other method-dependent information.
    """
    if method_name is None:
        if len(identified_estimand.backdoor_variables) != 0:  # If we have backdoor estimand
            if continuous_outcome:
                method_name = "backdoor.linear_regression"
            else:
                method_name = "backdoor.propensity_score_stratification"
        else:  # If no backdoor estimands
            if len(identified_estimand.instrumental_variables) != 0:  # If we have IV
                method_name = "iv.instrumental_variable"
            else:
                raise ValueError("Please specify method name")
    if method_name == "backdoor.generalized_linear_model":
      method_params = {"glm_family":sm.families.Binomial()}

    return model.estimate_effect(
        identified_estimand=identified_estimand,
        method_name=method_name,
        control_value=control_value,
        treatment_value=treatment_value,
        test_significance=test_significance,
        evaluate_effect_strength=evaluate_effect_strength,
        confidence_intervals=confidence_intervals,
        target_units=target_units,
        effect_modifiers=effect_modifiers,
        fit_estimator=fit_estimator,
        method_params=method_params
    )

def compute_estimates_dowhy(g, data, treatment, outcome, method_name):
  """
  g: a causal graph object
  data: a pandas dataframe
  treatment : treatment variable name
  outcome : outcome variable name
  method_name : from compute_effect function :
  * Propensity Score Matching: "backdoor.propensity_score_matching"
  * Propensity Score Stratification: "backdoor.propensity_score_stratification"
  * Propensity Score-based Inverse Weighting: "backdoor.propensity_score_weighting"
  * Linear Regression: "backdoor.linear_regression"
  * Generalized Linear Models (e.g., logistic regression): "backdoor.generalized_linear_model"
  * Instrumental Variables: "iv.instrumental_variable"
  * Regression Discontinuity: "iv.regression_discontinuity"

  """

  dict_of_estimates = {"ATT":0, "ATC":0, "ATE":0}
  #ATT
  model = create_model(g, data, treatment = treatment, outcome = outcome, estimand_type = "nonparametric-ate")
  id = find_effect(model)
  estimate_att = compute_effect(model, id, method_name = method_name, target_units = "att")
  dict_of_estimates["ATT"]=estimate_att.value
  #ATC
  estimate_atc = compute_effect(model, id, method_name = method_name, target_units = "atc")
  dict_of_estimates["ATC"]=estimate_atc.value
  #ATE
  estimate_ate = compute_effect(model, id, method_name = method_name, target_units = "ate")
  dict_of_estimates["ATE"]=estimate_ate.value

  return dict_of_estimates

def compute_direct_effect_dowhy(g, data, treatment, outcome, estimator = "linear_regression_estimator"):

  """ Computes the direct effect from the treatment to the outcome
  # g : an adjacency matrix
  # data : a pandas dataframe
  # treatment : the treatment variable
  # outcome : the outcome variable
  # estimator : estimator to compute the direct effect. Default: linear regression

  Other choices :
    - distance_matching_estimator :Simple matching estimator for binary treatments based on a distance
      metric.

    - generalized_linear_model_estimator : Compute effect of treatment using a generalized linear model such as logistic regression.
      Implementation uses statsmodels.api.GLM.
      Needs an additional parameter, "glm_family" to be specified in method_params.
      The value of this parameter can be any valid statsmodels.api families object.
      For example, to use logistic regression, specify "glm_family" as statsmodels.api.families.Binomial().

    - instrumental_variable_estimator : Compute effect of treatment using the instrumental variables method.

    - linear_regression_estimator : Compute effect of treatment using linear regression.
      Fits a regression model for estimating the outcome using treatment(s) and confounders. For a univariate treatment, the treatment effect is equivalent to the coefficient of the treatment variable.
      Simple method to show the implementation of a causal inference method that can handle multiple treatments and heterogeneity in treatment. Requires a strong assumption that all relationships from (T, W) to Y are linear.

    - propensity_score_matching_estimator : Estimate effect of treatment by finding matching treated and control
      units based on propensity score.
      Straightforward application of the back-door criterion.

    - propensity_score_stratification_estimator : Estimate effect of treatment by stratifying the data into bins with
      identical common causes.
      Straightforward application of the back-door criterion.

    - propensity_score_weighting_estimator : Estimate effect of treatment by weighing the data by
      inverse probability of occurrence.
      Straightforward application of the back-door criterion.

    - regression_discontinuity_estimator : Compute effect of treatment using the regression discontinuity method.
      Estimates effect by transforming the problem to an instrumental variables
      problem.

    - regression_estimator : Compute effect of treatment using some regression function.
      Fits a regression model for estimating the outcome using treatment(s) and
      confounders.
  """
  model = create_model(g, data, treatment = treatment, outcome = outcome, estimand_type = "nonparametric-nde")

  identified_estimand_nde = model.identify_effect(estimand_type="nonparametric-nde",
                                              proceed_when_unidentifiable=True)

  if estimator == "distance_matching_estimator":
    causal_estimator = dowhy.causal_estimators.distance_matching_estimator.DistanceMatchingEstimator
  elif estimator == "generalized_linear_model_estimator":
    causal_estimator = dowhy.causal_estimators.generalized_linear_model_estimator.GeneralizedLinearModelEstimator
    causal_estimate_nde = model.estimate_effect(identified_estimand_nde,
                                          method_name="mediation.two_stage_regression",
                                        confidence_intervals=False,
                                        test_significance=False,
                                          method_params = {
                                              'first_stage_model': causal_estimator,
                                              'second_stage_model': causal_estimator,
                                              "glm_family":sm.families.Binomial()
                                          }
                                        )
    return causal_estimate_nde.value

  elif estimator == "instrumental_variable_estimator":
      causal_estimator = dowhy.causal_estimators.instrumental_variable_estimator.InstrumentalVariableEstimator

  elif estimator == "linear_regression_estimator":
      causal_estimator = dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator

  elif estimator == "propensity_score_matching_estimator":
      causal_estimator = dowhy.causal_estimators.propensity_score_matching_estimator.PropensityScoreMatchingEstimator

  elif estimator == "propensity_score_stratification_estimator":
      causal_estimator = dowhy.causal_estimators.propensity_score_stratification_estimator.PropensityScoreStratificationEstimator

  elif estimator == "propensity_score_weighting_estimator":
      causal_estimator = dowhy.causal_estimators.propensity_score_weighting_estimator.PropensityScoreWeightingEstimator

  elif estimator == "regression_discontinuity_estimator":
      causal_estimator = dowhy.causal_estimators.regression_discontinuity_estimator.RegressionDiscontinuityEstimator

  elif estimator == "regression_estimator":
      causal_estimator = dowhy.causal_estimators.regression_estimator.RegressionEstimator

  else:
      raise ValueError("Invalid estimator choice. Please choose one of the valid options.")


  causal_estimate_nde = model.estimate_effect(identified_estimand_nde,
                                          method_name="mediation.two_stage_regression",
                                        confidence_intervals=False,
                                        test_significance=False,
                                          method_params = {
                                              'first_stage_model': causal_estimator,
                                              'second_stage_model': causal_estimator
                                          }
                                        )
  return causal_estimate_nde.value

def compute_indirect_effect_dowhy(g, data, treatment, outcome, estimator = "linear_regression_estimator"):

  """ Computes the direct effect from the treatment to the outcome
  # g : an adjacency matrix
  # data : a pandas dataframe
  # treatment : the treatment variable
  # outcome : the outcome variable
    # estimator : estimator to compute the direct effect. Default: linear regression

  Other choices :
    - distance_matching_estimator :Simple matching estimator for binary treatments based on a distance
      metric.

    - generalized_linear_model_estimator : Compute effect of treatment using a generalized linear model such as logistic regression.
      Implementation uses statsmodels.api.GLM.
      Needs an additional parameter, "glm_family" to be specified in method_params.
      The value of this parameter can be any valid statsmodels.api families object.
      For example, to use logistic regression, specify "glm_family" as statsmodels.api.families.Binomial().

    - instrumental_variable_estimator : Compute effect of treatment using the instrumental variables method.

    - linear_regression_estimator : Compute effect of treatment using linear regression.
      Fits a regression model for estimating the outcome using treatment(s) and confounders. For a univariate treatment, the treatment effect is equivalent to the coefficient of the treatment variable.
      Simple method to show the implementation of a causal inference method that can handle multiple treatments and heterogeneity in treatment. Requires a strong assumption that all relationships from (T, W) to Y are linear.

    - propensity_score_matching_estimator : Estimate effect of treatment by finding matching treated and control
      units based on propensity score.
      Straightforward application of the back-door criterion.

    - propensity_score_stratification_estimator : Estimate effect of treatment by stratifying the data into bins with
      identical common causes.
      Straightforward application of the back-door criterion.

    - propensity_score_weighting_estimator : Estimate effect of treatment by weighing the data by
      inverse probability of occurrence.
      Straightforward application of the back-door criterion.

    - regression_discontinuity_estimator : Compute effect of treatment using the regression discontinuity method.
      Estimates effect by transforming the problem to an instrumental variables
      problem.

    - regression_estimator : Compute effect of treatment using some regression function.
      Fits a regression model for estimating the outcome using treatment(s) and
      confounders.

  """
  model = create_model(g, data, treatment = treatment, outcome = outcome, estimand_type = "nonparametric-nie")

  identified_estimand_nie = model.identify_effect(estimand_type="nonparametric-nie",
                                              proceed_when_unidentifiable=True)
  if estimator == "distance_matching_estimator":
    causal_estimator = dowhy.causal_estimators.distance_matching_estimator.DistanceMatchingEstimator
  elif estimator == "generalized_linear_model_estimator":
    causal_estimator = dowhy.causal_estimators.generalized_linear_model_estimator.GeneralizedLinearModelEstimator
    causal_estimate_nie = model.estimate_effect(identified_estimand_nie,
                                          method_name="mediation.two_stage_regression",
                                        confidence_intervals=False,
                                        test_significance=False,
                                          method_params = {
                                              'first_stage_model': causal_estimator,
                                              'second_stage_model': causal_estimator,
                                              "glm_family":sm.families.Binomial()
                                          }
                                        )
    return causal_estimate_nie.value

  elif estimator == "instrumental_variable_estimator":
      causal_estimator = dowhy.causal_estimators.instrumental_variable_estimator.InstrumentalVariableEstimator

  elif estimator == "linear_regression_estimator":
      causal_estimator = dowhy.causal_estimators.linear_regression_estimator.LinearRegressionEstimator

  elif estimator == "propensity_score_matching_estimator":
      causal_estimator = dowhy.causal_estimators.propensity_score_matching_estimator.PropensityScoreMatchingEstimator

  elif estimator == "propensity_score_stratification_estimator":
      causal_estimator = dowhy.causal_estimators.propensity_score_stratification_estimator.PropensityScoreStratificationEstimator

  elif estimator == "propensity_score_weighting_estimator":
      causal_estimator = dowhy.causal_estimators.propensity_score_weighting_estimator.PropensityScoreWeightingEstimator

  elif estimator == "regression_discontinuity_estimator":
      causal_estimator = dowhy.causal_estimators.regression_discontinuity_estimator.RegressionDiscontinuityEstimator

  elif estimator == "regression_estimator":
      causal_estimator = dowhy.causal_estimators.regression_estimator.RegressionEstimator

  else:
      raise ValueError("Invalid estimator choice. Please choose one of the valid options.")

  causal_estimate_nie = model.estimate_effect(identified_estimand_nie,
                                          method_name="mediation.two_stage_regression",
                                        confidence_intervals=False,
                                        test_significance=False,
                                          method_params = {
                                              'first_stage_model': causal_estimator,
                                              'second_stage_model': causal_estimator
                                          }
                                        )
  return causal_estimate_nie.value

# Load the data

file_path="adult_cleaned_bin.csv"
dataset, labels = load_and_check_data(file_path)

# The dowhy function modifies the dataset, thus, we will create a dowhy dataset, and another for later purposes
dowhy_data = pd.read_csv(file_path)

#Run PC and get a causalgraph
g=run_ges(dataset)
g=delete_path(g,labels,["hours_per_week","Sex"])
draw_graph(g, labels, filename = "newgraph")

# Compute ATE, ATC, ATT
dict_of_estimates = compute_estimates_dowhy(g,dowhy_data, treatment = "workclass", outcome = "occupation", method_name = "backdoor.generalized_linear_model")
print(dict_of_estimates)
#Compute Direct Effect
direct_effect = compute_direct_effect_dowhy(g, dowhy_data, treatment = "workclass", outcome = "occupation", estimator = "generalized_linear_model_estimator")
print("Direct effect from treatment to outcome =", direct_effect)
#Compute Indirect Effect
indirect_effect = compute_indirect_effect_dowhy(g, dowhy_data, treatment = "workclass", outcome = "occupation", estimator = "generalized_linear_model_estimator")
print("Indirect effect from treatment to outcome =", indirect_effect)